{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import codecs # for word encoding\n",
    "import glob # for regular expressions\n",
    "import multiprocessing # concurrency\n",
    "import os # os stuff, like reading a file\n",
    "import pprint # pretty printing\n",
    "import re # regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import external libraries\n",
    "import nltk # natural language procession\n",
    "import gensim.models.word2vec as w2v # word 2 vec\n",
    "import sklearn.manifold #dimensionality reduction\n",
    "import numpy as np # math\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bergsfamily/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bergsfamily/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - process the data\n",
    "# clean data\n",
    "\n",
    "nltk.download('punkt') # pretrained tokenizer\n",
    "nltk.download('stopwords') # words like and, the, a, an, of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/got1.txt',\n",
       " 'data/got2.txt',\n",
       " 'data/got3.txt',\n",
       " 'data/got4.txt',\n",
       " 'data/got5.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the book filenames\n",
    "book_filenames = sorted(glob.glob(\"data/*.txt\"))\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'data/got1.txt'...\n",
      "Corpus in now 1770659 characters long\n",
      "\n",
      "Reading 'data/got2.txt'...\n",
      "Corpus in now 4071041 characters long\n",
      "\n",
      "Reading 'data/got3.txt'...\n",
      "Corpus in now 6391405 characters long\n",
      "\n",
      "Reading 'data/got4.txt'...\n",
      "Corpus in now 8107945 characters long\n",
      "\n",
      "Reading 'data/got5.txt'...\n",
      "Corpus in now 9719485 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus in now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "#returns list of words, removes puncutation and hyphens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence where each word is tokenized\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heraldic crest by Virginia Norey.\n",
      "[u'Heraldic', u'crest', u'by', u'Virginia', u'Norey']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[5])\n",
    "print(sentence_to_wordlist(raw_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 1,818,103 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word 2 Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2 - build the models\n",
    "# 3 tasks vectors help with\n",
    "# Distance, Similarity, Ranking\n",
    "\n",
    "\n",
    "# define hyperparameters\n",
    "num_features = 300 # more features = more expensive to train, but more accurate\n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count() # more workers = faster training\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "# between 0 and 1e-5 \n",
    "# how often to use\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for random number generator\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thrones2vec = w2v.Word2Vec(\n",
    "    sg = 1,\n",
    "    seed = seed,\n",
    "    workers = num_workers,\n",
    "    size = num_features,\n",
    "    min_count = min_word_count,\n",
    "    window = context_size,\n",
    "    sample = downsampling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thrones2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 17277\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7021920"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thrones2vec.save(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model - Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model - in case this is re-run\n",
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"thrones2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKIP\n",
    "## Compress word vectors into 2D space and plot\n",
    "\n",
    "**TSNE has been giving me headaches on my mac, so skip the plotting**\n",
    "\n",
    "See https://github.com/scikit-learn/scikit-learn/issues/7089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tsne = sklearn.manifold.TSNE(n_components=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_word_vectors_matrix = thrones2vec.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Explore semantic similarities between book characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Eddard', 0.7412210702896118),\n",
       " (u'Winterfell', 0.6834571361541748),\n",
       " (u'Karstark', 0.6381300687789917),\n",
       " (u'Lyanna', 0.6353175044059753),\n",
       " (u'direwolf', 0.6259804964065552),\n",
       " (u'beheaded', 0.6252360343933105),\n",
       " (u'executed', 0.61602783203125),\n",
       " (u'Hornwood', 0.6131395697593689),\n",
       " (u'Benjen', 0.607450008392334),\n",
       " (u'Dustin', 0.6061956286430359)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"Stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Jaehaerys', 0.7929835915565491),\n",
       " (u'Daeron', 0.7739320993423462),\n",
       " (u'reign', 0.7709693908691406),\n",
       " (u'Mad', 0.7663239240646362),\n",
       " (u'Usurper', 0.7441689372062683),\n",
       " (u'Unworthy', 0.7324290871620178),\n",
       " (u'Elia', 0.7324237823486328),\n",
       " (u'appointment', 0.7277305126190186),\n",
       " (u'Conqueror', 0.7227622270584106),\n",
       " (u'Cruel', 0.717417299747467)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"Aerys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'wolf', 0.6745015382766724),\n",
       " (u'Rickon', 0.6481422781944275),\n",
       " (u'Ghost', 0.6333140134811401),\n",
       " (u'Stark', 0.6259804964065552),\n",
       " (u'pup', 0.620887041091919),\n",
       " (u'SHAGGYDOG', 0.6180346608161926),\n",
       " (u'ranger', 0.6159267425537109),\n",
       " (u'GHOST', 0.6146520376205444),\n",
       " (u'wight', 0.5989304780960083),\n",
       " (u'standard', 0.5985522866249084)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"direwolf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'five', 0.7831581830978394),\n",
       " (u'thirty', 0.7753496170043945),\n",
       " (u'Six', 0.7512350678443909),\n",
       " (u'twenty', 0.7498271465301514),\n",
       " (u'forty', 0.7492700815200806),\n",
       " (u'six', 0.7487969994544983),\n",
       " (u'Two', 0.7451422214508057),\n",
       " (u'sixty', 0.7449865937232971),\n",
       " (u'eight', 0.7405045032501221),\n",
       " (u'Eight', 0.734088659286499)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.most_similar(\"four\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = thrones2vec.most_similar_cosmul(\n",
    "        positive = [end2, start1],\n",
    "        negative = [end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stark is related to Winterfell, as Tully is related to Riverrun\n",
      "Jaime is related to sword, as dreamwine is related to wine\n",
      "Arya is related to Nymeria, as Dany is related to dragons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Dany'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"Stark\", \"Winterfell\", \"Riverrun\")\n",
    "nearest_similarity_cosmul(\"Jaime\", \"sword\", \"wine\")\n",
    "nearest_similarity_cosmul(\"Arya\", \"Nymeria\", \"dragons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
