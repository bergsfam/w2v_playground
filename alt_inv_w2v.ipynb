{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import codecs # for word encoding\n",
    "import glob # for regular expressions\n",
    "import multiprocessing # concurrency\n",
    "import os # os stuff, like reading a file\n",
    "import pprint # pretty printing\n",
    "import re # regular expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import external libraries\n",
    "import nltk # natural language procession\n",
    "import gensim.models.word2vec as w2v # word 2 vec\n",
    "import sklearn.manifold #dimensionality reduction\n",
    "import numpy as np # math\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bergsfamily/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bergsfamily/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - process the data\n",
    "# clean data\n",
    "\n",
    "nltk.download('punkt') # pretrained tokenizer\n",
    "nltk.download('stopwords') # words like and, the, a, an, of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_alt_inv/alt_inv_ch01.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the book filenames\n",
    "book_filenames = sorted(glob.glob(\"data_alt_inv/*.txt\"))\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'data_alt_inv/alt_inv_ch01.txt'...\n",
      "Corpus in now 60389 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus in now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "#returns list of words, removes puncutation and hyphens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence where each word is tokenized\n",
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip to content\n",
      "Safari Home\n",
      "Recommended\n",
      "Queue\n",
      "History\n",
      "Topics\n",
      "Tutorials\n",
      "Offers & Deals\n",
      "Newsletters\n",
      "Highlights\n",
      "Settings\n",
      "Support\n",
      "Sign Out\n",
      "Table of Contents for  Alternative Investments: CAIA Level I, 3rd Edition\n",
      "CLOSE\n",
      "Cover image for Alternative Investments: CAIA Level I, 3rd Edition\n",
      " publisher logo Alternative Investments: CAIA Level I, 3rd Edition\n",
      "by Donald R. Chambers; Hossein Kazemi; CAIA Association; Mark J. P. Anson; Keith H. Black\n",
      "Published by John Wiley & Sons, 2015\n",
      "Preface (05:45 mins)\n",
      "Acknowledgments (01:09 mins)\n",
      "About the Authors (02:18 mins)\n",
      "PART 1 Introduction to Alternative Investments\n",
      " CHAPTER 1 What Is an Alternative Investment?\n",
      "[u'Skip', u'to', u'content', u'Safari', u'Home', u'Recommended', u'Queue', u'History', u'Topics', u'Tutorials', u'Offers', u'Deals', u'Newsletters', u'Highlights', u'Settings', u'Support', u'Sign', u'Out', u'Table', u'of', u'Contents', u'for', u'Alternative', u'Investments', u'CAIA', u'Level', u'I', u'rd', u'Edition', u'CLOSE', u'Cover', u'image', u'for', u'Alternative', u'Investments', u'CAIA', u'Level', u'I', u'rd', u'Edition', u'publisher', u'logo', u'Alternative', u'Investments', u'CAIA', u'Level', u'I', u'rd', u'Edition', u'by', u'Donald', u'R', u'Chambers', u'Hossein', u'Kazemi', u'CAIA', u'Association', u'Mark', u'J', u'P', u'Anson', u'Keith', u'H', u'Black', u'Published', u'by', u'John', u'Wiley', u'Sons', u'Preface', u'mins', u'Acknowledgments', u'mins', u'About', u'the', u'Authors', u'mins', u'PART', u'Introduction', u'to', u'Alternative', u'Investments', u'CHAPTER', u'What', u'Is', u'an', u'Alternative', u'Investment']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[0])\n",
    "print(sentence_to_wordlist(raw_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 8,749 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word 2 Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2 - build the models\n",
    "# 3 tasks vectors help with\n",
    "# Distance, Similarity, Ranking\n",
    "\n",
    "\n",
    "# define hyperparameters\n",
    "num_features = 300 # more features = more expensive to train, but more accurate\n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count() # more workers = faster training\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "# between 0 and 1e-5 \n",
    "# how often to use\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for random number generator\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "altinv2vec = w2v.Word2Vec(\n",
    "    sg = 1,\n",
    "    seed = seed,\n",
    "    workers = num_workers,\n",
    "    size = num_features,\n",
    "    min_count = min_word_count,\n",
    "    window = context_size,\n",
    "    sample = downsampling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "altinv2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 545\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(altinv2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23751"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altinv2vec.train(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "altinv2vec.save(os.path.join(\"trained\", \"altinv2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model - Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model - in case this is re-run\n",
    "altinv2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"altinv2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Explore semantic similarities between book characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Funds', 0.9999245405197144),\n",
       " (u'Equity', 0.9998708963394165),\n",
       " (u'Real', 0.9997694492340088),\n",
       " (u'PART', 0.9997391700744629),\n",
       " (u'Foundations', 0.9996857643127441),\n",
       " (u'Risk', 0.9996431469917297),\n",
       " (u'Private', 0.9994067549705505),\n",
       " (u'Credit', 0.9992772936820984),\n",
       " (u'Investments', 0.9992425441741943),\n",
       " (u'Management', 0.9991354942321777)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altinv2vec.most_similar(\"Hedge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'PART', 0.9998748302459717),\n",
       " (u'Risk', 0.999846875667572),\n",
       " (u'Equity', 0.9998409152030945),\n",
       " (u'Foundations', 0.999832034111023),\n",
       " (u'Funds', 0.9998094439506531),\n",
       " (u'Hedge', 0.9997694492340088),\n",
       " (u'Private', 0.9996858835220337),\n",
       " (u'Credit', 0.9996574521064758),\n",
       " (u'Management', 0.9995602965354919),\n",
       " (u'Assets', 0.9995435476303101)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altinv2vec.most_similar(\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'standard', 0.9998104572296143),\n",
       " (u'absolute', 0.9998100399971008),\n",
       " (u'rather', 0.9998042583465576),\n",
       " (u'category', 0.9998033046722412),\n",
       " (u'believed', 0.9998025298118591),\n",
       " (u'then', 0.9998018741607666),\n",
       " (u'arbitrage', 0.9998009204864502),\n",
       " (u'different', 0.9997997283935547),\n",
       " (u'there', 0.9997996687889099),\n",
       " (u'equities', 0.9997979402542114)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altinv2vec.most_similar(\"commodities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'not', 0.9997887015342712),\n",
       " (u'is', 0.9997864961624146),\n",
       " (u'to', 0.9997845888137817),\n",
       " (u'the', 0.9997729659080505),\n",
       " (u'a', 0.99976646900177),\n",
       " (u'or', 0.9997627139091492),\n",
       " (u'on', 0.9997608661651611),\n",
       " (u'that', 0.9997460246086121),\n",
       " (u'through', 0.9997372031211853),\n",
       " (u'which', 0.9997333288192749)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altinv2vec.most_similar(\"investment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = altinv2vec.most_similar_cosmul(\n",
    "        positive = [end2, start1],\n",
    "        negative = [end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nearest_similarity_cosmul(\"Rusty\", \"Firestar\", \"Graystripe\")\n",
    "#nearest_similarity_cosmul(\"Thunderclan\", \"Riverclan\", \"Firestar\")\n",
    "#nearest_similarity_cosmul(\"Thunderclan\", \"Bluestar\", \"Graystripe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
